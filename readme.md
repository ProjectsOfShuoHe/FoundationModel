**Paper list for Robustness and Security in Foundation Models:**

**Survey:**

**[1]** DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. [http://arxiv.org/abs/2306.11698]

**[2]** PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. [http://arxiv.org/abs/2306.04528]

**Robustness in LLMs:**

**[1]** Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations. [http://arxiv.org/abs/2306.04618]

**[2]** 

**Security in LLMs:**

**[3]** 

**[4]** 

**Robustness in vision-language models:**

**[1]** On Evaluating Adversarial Robustness of Large Vision-Language Models. [http://arxiv.org/abs/2305.16934]

**[2]** Towards Robust Prompts on Vision-Language Models. [http://arxiv.org/abs/2304.08479]

**Robustness in vision models:**


